INFO:/home/dimweb/Desktop/deeppavlov/FoCus/train_focus.py:Arguments: Namespace(model_name='BART', gpt2_model_path='gpt2', bart_model_path='facebook/bart-base', train_dataset_path='data/train_focus.json', train_dataset_cache='data/focus_cache.tar.gz', dev_dataset_path='data/valid_focus.json', dev_dataset_cache='data/focus_cache.tar.gz', ps_coef=1.0, kn_coef=1.0, lm_coef=10.0, max_history=1, train_batch_size=2, valid_batch_size=1, gradient_accumulation_steps=16, lr=6.25e-05, max_norm=1.0, n_epochs=2, eval_before_start=False, inference=False, test_infer=False, device='cuda', fp16='', local_rank=-1, gpu_start_num=1, flag='E2_L10', seed=19950604, random_knowledge=False, incontext=True)
INFO:/home/dimweb/Desktop/deeppavlov/FoCus/train_focus.py:Prepare tokenizer, pretrained model and optimizer.
Some weights of BARTPK_ctxt were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['attn2.bias', 'concat_summary.summary.bias', 'summary.summary.bias', 'summary.summary.weight', 'concat_summary.summary.weight', 'attn2.weight', 'final_logits_bias', 'attn1.bias', 'attn1.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/dimweb/Desktop/deeppavlov/d_env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:/home/dimweb/Desktop/deeppavlov/FoCus/train_focus.py:Prepare datasets
INFO:/home/dimweb/Desktop/deeppavlov/FoCus/utils_focus.py:Load tokenized dataset from cache at data/focus_cache.tar.gz_train_focus_BartTokenizer
INFO:/home/dimweb/Desktop/deeppavlov/FoCus/data_utils.py:Build inputs and labels
INFO:/home/dimweb/Desktop/deeppavlov/FoCus/data_utils.py:Pad inputs and convert to Tensor
INFO:/home/dimweb/Desktop/deeppavlov/FoCus/data_utils.py:Build train and validation dataloaders
INFO:/home/dimweb/Desktop/deeppavlov/FoCus/data_utils.py:Train dataset (Batch, Candidates, Seq length): torch.Size([70332, 123])
INFO:/home/dimweb/Desktop/deeppavlov/FoCus/data_utils.py:Valid dataset (Batch, Candidates, Seq length): torch.Size([5639, 112])
INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=2.
orig num 50265 num_added 4
train 12484
valid 1000
remove list:  0
remove list:  0
[1/35166]   0%|           [00:00<?]Epoch [1/2]: [1/35166]   0%|           [00:00<?]Epoch [1/2]: [1/35166]   0%|          , lm_loss=7.99 [00:00<?]Epoch [1/2]: [1/35166]   0%|          , lm_loss=7.99 [00:00<?]Epoch [1/2]: [1/35166]   0%|          , lm_loss=7.95 [00:00<?]Epoch [1/2]: [2/35166]   0%|          , lm_loss=7.95 [00:00<5:42:00]Epoch [1/2]: [2/35166]   0%|          , lm_loss=7.95 [00:01<5:42:00]Epoch [1/2]: [2/35166]   0%|          , lm_loss=7.92 [00:01<5:42:00]Epoch [1/2]: [3/35166]   0%|          , lm_loss=7.92 [00:01<5:41:35]Epoch [1/2]: [3/35166]   0%|          , lm_loss=7.92 [00:01<5:41:35]Epoch [1/2]: [3/35166]   0%|          , lm_loss=7.91 [00:01<5:41:35]Epoch [1/2]: [4/35166]   0%|          , lm_loss=7.91 [00:01<5:41:21]Epoch [1/2]: [4/35166]   0%|          , lm_loss=7.91 [00:02<5:41:21]Epoch [1/2]: [4/35166]   0%|          , lm_loss=7.88 [00:02<5:41:21]Epoch [1/2]: [5/35166]   0%|          , lm_loss=7.88 [00:02<5:42:03]Epoch [1/2]: [5/35166]   0%|          , lm_loss=7.88 [00:02<5:42:03]Epoch [1/2]: [5/35166]   0%|          , lm_loss=7.86 [00:02<5:42:03]Epoch [1/2]: [6/35166]   0%|          , lm_loss=7.86 [00:02<5:42:08]Epoch [1/2]: [6/35166]   0%|          , lm_loss=7.86 [00:03<5:42:08]Epoch [1/2]: [6/35166]   0%|          , lm_loss=7.83 [00:03<5:42:08]Epoch [1/2]: [7/35166]   0%|          , lm_loss=7.83 [00:03<5:42:29]Epoch [1/2]: [7/35166]   0%|          , lm_loss=7.83 [00:04<5:42:29]Epoch [1/2]: [7/35166]   0%|          , lm_loss=7.82 [00:04<5:42:29]Epoch [1/2]: [8/35166]   0%|          , lm_loss=7.82 [00:04<5:42:29]Epoch [1/2]: [8/35166]   0%|          , lm_loss=7.82 [00:04<5:42:29]Epoch [1/2]: [8/35166]   0%|          , lm_loss=7.81 [00:04<5:42:29]Epoch [1/2]: [9/35166]   0%|          , lm_loss=7.81 [00:04<5:42:17]Epoch [1/2]: [9/35166]   0%|          , lm_loss=7.81 [00:05<5:42:17]Epoch [1/2]: [9/35166]   0%|          , lm_loss=7.8 [00:05<5:42:17] Epoch [1/2]: [10/35166]   0%|          , lm_loss=7.8 [00:05<5:42:19]Epoch [1/2]: [10/35166]   0%|          , lm_loss=7.8 [00:05<5:42:19]Epoch [1/2]: [10/35166]   0%|          , lm_loss=7.8 [00:05<5:42:19]Epoch [1/2]: [11/35166]   0%|          , lm_loss=7.8 [00:05<5:42:25]Epoch [1/2]: [11/35166]   0%|          , lm_loss=7.8 [00:06<5:42:25]Epoch [1/2]: [11/35166]   0%|          , lm_loss=7.74 [00:06<5:42:25]Epoch [1/2]: [12/35166]   0%|          , lm_loss=7.74 [00:06<5:42:38]Epoch [1/2]: [12/35166]   0%|          , lm_loss=7.74 [00:07<5:42:38]Epoch [1/2]: [12/35166]   0%|          , lm_loss=7.75 [00:07<5:42:38]Epoch [1/2]: [13/35166]   0%|          , lm_loss=7.75 [00:07<5:42:39]Epoch [1/2]: [13/35166]   0%|          , lm_loss=7.75 [00:07<5:42:39]Epoch [1/2]: [13/35166]   0%|          , lm_loss=7.75 [00:07<5:42:39]Epoch [1/2]: [14/35166]   0%|          , lm_loss=7.75 [00:07<5:42:41]Epoch [1/2]: [14/35166]   0%|          , lm_loss=7.75 [00:08<5:42:41]Epoch [1/2]: [14/35166]   0%|          , lm_loss=7.73 [00:08<5:42:41]Epoch [1/2]: [15/35166]   0%|          , lm_loss=7.73 [00:08<5:42:32]Epoch [1/2]: [15/35166]   0%|          , lm_loss=7.73 [00:08<5:42:32]Epoch [1/2]: [15/35166]   0%|          , lm_loss=7.75 [00:08<5:42:32]Epoch [1/2]: [16/35166]   0%|          , lm_loss=7.75 [00:08<5:49:27]Epoch [1/2]: [16/35166]   0%|          , lm_loss=7.75 [00:09<5:49:27]Epoch [1/2]: [16/35166]   0%|          , lm_loss=7.69 [00:09<5:49:27]Epoch [1/2]: [17/35166]   0%|          , lm_loss=7.69 [00:09<5:50:44]Epoch [1/2]: [17/35166]   0%|          , lm_loss=7.69 [00:10<5:50:44]Epoch [1/2]: [17/35166]   0%|          , lm_loss=7.64 [00:10<5:50:44]Epoch [1/2]: [18/35166]   0%|          , lm_loss=7.64 [00:10<5:52:41]Epoch [1/2]: [18/35166]   0%|          , lm_loss=7.64 [00:10<5:52:41]Epoch [1/2]: [18/35166]   0%|          , lm_loss=7.6 [00:10<5:52:41] Epoch [1/2]: [19/35166]   0%|          , lm_loss=7.6 [00:10<5:54:20]Epoch [1/2]: [19/35166]   0%|          , lm_loss=7.6 [00:11<5:54:20]Epoch [1/2]: [19/35166]   0%|          , lm_loss=7.55 [00:11<5:54:20]Epoch [1/2]: [20/35166]   0%|          , lm_loss=7.55 [00:11<5:55:28]Epoch [1/2]: [20/35166]   0%|          , lm_loss=7.55 [00:11<5:55:28]Epoch [1/2]: [20/35166]   0%|          , lm_loss=7.52 [00:11<5:55:28]Epoch [1/2]: [21/35166]   0%|          , lm_loss=7.52 [00:11<5:55:50]Epoch [1/2]: [21/35166]   0%|          , lm_loss=7.52 [00:12<5:55:50]Epoch [1/2]: [21/35166]   0%|          , lm_loss=7.49 [00:12<5:55:50]Epoch [1/2]: [22/35166]   0%|          , lm_loss=7.49 [00:12<5:56:37]Epoch [1/2]: [22/35166]   0%|          , lm_loss=7.49 [00:13<5:56:37]Epoch [1/2]: [22/35166]   0%|          , lm_loss=7.45 [00:13<5:56:37]Epoch [1/2]: [23/35166]   0%|          , lm_loss=7.45 [00:13<5:57:13]Epoch [1/2]: [23/35166]   0%|          , lm_loss=7.45 [00:13<5:57:13]Epoch [1/2]: [23/35166]   0%|          , lm_loss=7.41 [00:13<5:57:13]Epoch [1/2]: [24/35166]   0%|          , lm_loss=7.41 [00:13<5:57:25]Epoch [1/2]: [24/35166]   0%|          , lm_loss=7.41 [00:14<5:57:25]Epoch [1/2]: [24/35166]   0%|          , lm_loss=7.35 [00:14<5:57:25]Epoch [1/2]: [25/35166]   0%|          , lm_loss=7.35 [00:14<5:56:57]Epoch [1/2]: [25/35166]   0%|          , lm_loss=7.35 [00:14<5:56:57]Epoch [1/2]: [25/35166]   0%|          , lm_loss=7.33 [00:14<5:56:57]Epoch [1/2]: [26/35166]   0%|          , lm_loss=7.33 [00:14<5:56:35]Epoch [1/2]: [26/35166]   0%|          , lm_loss=7.33 [00:15<5:56:35]Epoch [1/2]: [26/35166]   0%|          , lm_loss=7.32 [00:15<5:56:35]Epoch [1/2]: [27/35166]   0%|          , lm_loss=7.32 [00:15<5:57:02]Epoch [1/2]: [27/35166]   0%|          , lm_loss=7.32 [00:16<5:57:02]Epoch [1/2]: [27/35166]   0%|          , lm_loss=7.26 [00:16<5:57:02]Epoch [1/2]: [28/35166]   0%|          , lm_loss=7.26 [00:16<5:58:21]Epoch [1/2]: [28/35166]   0%|          , lm_loss=7.26 [00:16<5:58:21]Epoch [1/2]: [28/35166]   0%|          , lm_loss=7.21 [00:16<5:58:21]Epoch [1/2]: [29/35166]   0%|          , lm_loss=7.21 [00:16<5:54:12]Epoch [1/2]: [29/35166]   0%|          , lm_loss=7.21 [00:17<5:54:12]Epoch [1/2]: [29/35166]   0%|          , lm_loss=7.17 [00:17<5:54:12]Epoch [1/2]: [30/35166]   0%|          , lm_loss=7.17 [00:17<5:51:26]Epoch [1/2]: [30/35166]   0%|          , lm_loss=7.17 [00:17<5:51:26]Epoch [1/2]: [30/35166]   0%|          , lm_loss=7.13 [00:17<5:51:26]Epoch [1/2]: [31/35166]   0%|          , lm_loss=7.13 [00:17<5:49:25]Epoch [1/2]: [31/35166]   0%|          , lm_loss=7.13 [00:18<5:49:25]Epoch [1/2]: [31/35166]   0%|          , lm_loss=7.12 [00:18<5:49:25]Epoch [1/2]: [32/35166]   0%|          , lm_loss=7.12 [00:18<5:54:14]Epoch [1/2]: [32/35166]   0%|          , lm_loss=7.12 [00:19<5:54:14]Epoch [1/2]: [32/35166]   0%|          , lm_loss=7.09 [00:19<5:54:14]Epoch [1/2]: [33/35166]   0%|          , lm_loss=7.09 [00:19<5:51:18]Epoch [1/2]: [33/35166]   0%|          , lm_loss=7.09 [00:19<5:51:18]Epoch [1/2]: [33/35166]   0%|          , lm_loss=7.05 [00:19<5:51:18]Epoch [1/2]: [34/35166]   0%|          , lm_loss=7.05 [00:19<5:49:18]Epoch [1/2]: [34/35166]   0%|          , lm_loss=7.05 [00:20<5:49:18]Epoch [1/2]: [34/35166]   0%|          , lm_loss=7.02 [00:20<5:49:18]Epoch [1/2]: [35/35166]   0%|          , lm_loss=7.02 [00:20<5:47:50]Epoch [1/2]: [35/35166]   0%|          , lm_loss=7.02 [00:20<5:47:50]Epoch [1/2]: [35/35166]   0%|          , lm_loss=6.98 [00:20<5:47:50]Epoch [1/2]: [36/35166]   0%|          , lm_loss=6.98 [00:20<5:46:57]